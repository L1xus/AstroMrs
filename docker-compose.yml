version: '3'
x-airflow-common:
  &airflow-common
  build:
    context: .
    dockerfile: Dockerfile
  env_file:
    - airflow.env
  volumes:
    - .:/opt/airflow/AstroMRS
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
  user: "${AIRFLOW_UID:-50000}:0"
  depends_on:
    - postgres
  networks:
    - movie-net

services:
  mongodb:
    image: mongo
    ports:
      - "27017:27017"
    networks:
      - movie-net

  spark-master:
    image: bitnami/spark:3.5.1
    command: bash -c "pip install pymongo requests && bin/spark-class org.apache.spark.deploy.master.Master"
    ports:
      - "9090:8080"
      - "7077:7077"
    environment:
      PYTHONPATH: '/opt/bitnami/spark'
    volumes:
      - ./src:/opt/bitnami/spark/src
    networks:
      - movie-net

  spark-worker-1:
    image: bitnami/spark:3.5.1
    command: bash -c "pip install pymongo requests && bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077"
    environment: 
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_MODE: worker
      SPARK_WORKER_CORES: 2 
      SPARK_WORKER_MEMORY: 2G
      PYTHONPATH: '/opt/bitnami/spark'
    volumes:
      - ./src:/opt/bitnami/spark/src
    depends_on: 
      - spark-master
    networks:
      - movie-net

  spark-worker-2:
    image: bitnami/spark:3.5.1
    command: bash -c "pip install pymongo requests && bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077"
    environment: 
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_MODE: worker
      SPARK_WORKER_CORES: 2 
      SPARK_WORKER_MEMORY: 2G
      PYTHONPATH: '/opt/bitnami/spark'
    volumes:
      - ./src:/opt/bitnami/spark/src
    depends_on: 
      - spark-master
    networks:
      - movie-net

  postgres:
    image: postgres:14.0
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    networks:
      - movie-net
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      retries: 5
      start_period: 5s
    restart: always

  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      - airflow-init

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    depends_on: 
      - airflow-init

  airflow-init:
    <<: *airflow-common
    command: bash -c "airflow db migrate && airflow users create \
      --username $${AIRFLOW_ADMIN_USERNAME} \
      --firstname $${AIRFLOW_ADMIN_FIRSTNAME} \
      --lastname $${AIRFLOW_ADMIN_LASTNAME} \
      --role $${AIRFLOW_ADMIN_ROLE} \
      --email $${AIRFLOW_ADMIN_EMAIL} \
      --password $${AIRFLOW_ADMIN_PASSWORD}"
    depends_on:
      - postgres

volumes:
  postgres-db-volume:

networks:
  movie-net:
